{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UK Holiday Shopper Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing yocuda data from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = (spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"gs://ds-mlengine/praneeth/2017_Yocuda_Dummy_Data_V01_20180129.csv\"))\\\n",
    "       .filter((to_date(col(\"timestamp\"))>'2016-11-30') & (to_date(col(\"timestamp\"))<'2017-12-01'))\\\n",
    "  .selectExpr(\"identifier\",\"item_total\",\"transaction_id\",\"to_date(timestamp) as date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('identifier', 'string'),\n",
       " ('item_total', 'double'),\n",
       " ('transaction_id', 'string'),\n",
       " ('date', 'date')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing UK Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import (\n",
    "    AbstractHolidayCalendar, DateOffset, EasterMonday,\n",
    "    GoodFriday, Holiday, MO,\n",
    "    next_monday, next_monday_or_tuesday)\n",
    "class EnglandAndWalesHolidayCalendar(AbstractHolidayCalendar):\n",
    "    rules = [\n",
    "        Holiday('New Years Day', month=1, day=1, observance=next_monday),\n",
    "        GoodFriday,\n",
    "        EasterMonday,\n",
    "        Holiday('Early May bank holiday',\n",
    "                month=5, day=1, offset=DateOffset(weekday=MO(1))),\n",
    "        Holiday('Spring bank holiday',\n",
    "                month=5, day=31, offset=DateOffset(weekday=MO(-1))),\n",
    "        Holiday('Summer bank holiday',\n",
    "                month=8, day=31, offset=DateOffset(weekday=MO(-1))),\n",
    "        Holiday('Christmas Day', month=12, day=25, observance=next_monday),\n",
    "        Holiday('Boxing Day',\n",
    "                month=12, day=26, observance=next_monday_or_tuesday)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering (Holiday -2 days) to (Holiday + 1 day) as Holiday period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DatetimeIndex, datetime\n",
    "from pandas.tseries.holiday import get_calendar\n",
    "from pyspark.sql.functions import to_date\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "holidays = EnglandAndWalesHolidayCalendar().holidays(start=date(2016, 11, 30),end=date(2017, 12, 1))\n",
    "holidays.tolist()\n",
    "\n",
    "list_of_holidays = sqlContext.createDataFrame(\n",
    "    [(str(x - timedelta(days = 2)),str(x - timedelta(days = 1)),str(x),str(x + timedelta(days = 1))) for x in holidays],\n",
    "    ['date_sub_2','date_sub_1','date','date_add_1']\n",
    "    )\\\n",
    ".selectExpr('to_date(date_sub_2) as date_sub_2','to_date(date_sub_1) as date_sub_1','to_date(date) as date','to_date(date_add_1) as date_add_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consolidating holiday dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|      date|holiday_indicator|\n",
      "+----------+-----------------+\n",
      "|2017-04-29|                1|\n",
      "|2017-04-12|                1|\n",
      "|2017-05-27|                1|\n",
      "|2017-01-01|                1|\n",
      "|2017-04-18|                1|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "list_of_holidays_v2 = list_of_holidays.selectExpr('date_sub_2 as date')\\\n",
    ".union(list_of_holidays.selectExpr('date_sub_1 as date'))\\\n",
    ".union(list_of_holidays.selectExpr('date as date'))\\\n",
    ".union(list_of_holidays.selectExpr('date_add_1 as date'))\\\n",
    ".distinct()\\\n",
    ".withColumn('holiday_indicator', lit(1))\n",
    "list_of_holidays_v2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('date', 'date'), ('holiday_indicator', 'int')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_holidays_v2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining the holiday dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+--------------------+-----------------+\n",
      "|      date|identifier|item_total|      transaction_id|holiday_indicator|\n",
      "+----------+----------+----------+--------------------+-----------------+\n",
      "|2017-04-29| suv@a.com|     148.0|2017-04-29 - E169...|                1|\n",
      "|2017-04-29|      null|      60.0|2017-04-29 - B121...|                1|\n",
      "|2017-04-29| oeh@f.com|    115.98|2017-04-29 - B175...|                1|\n",
      "|2017-04-29| nlw@d.com|      44.0|2017-04-29 - F116...|                1|\n",
      "|2017-04-29| uzy@b.com|     48.99|2017-04-29 - B162...|                1|\n",
      "+----------+----------+----------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.registerTempTable(\"data\")\n",
    "base_data=data.join(list_of_holidays_v2,[\"date\"],\"left\")\n",
    "base_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating metrics of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------------+------------+\n",
      "|identifier|total_spend|total_txns|holiday_spends|holiday_txns|\n",
      "+----------+-----------+----------+--------------+------------+\n",
      "| ajb@b.com|        6.0|         1|          null|        null|\n",
      "| bee@f.com|       32.0|         1|          null|        null|\n",
      "| bnx@a.com|     679.98|         1|          null|        null|\n",
      "| buv@e.com|     329.22|         1|          null|        null|\n",
      "| ccj@e.com|       5.05|         1|          null|        null|\n",
      "+----------+-----------+----------+--------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=base_data.filter((col(\"identifier\").isNotNull()) & \\\n",
    "                  (col(\"item_total\")>0))  \\\n",
    "            .groupBy(\"identifier\").agg(sum(\"item_total\").alias(\"total_spend\"),countDistinct(\"transaction_id\").alias(\"total_txns\"))\n",
    "\n",
    "df2=base_data.filter((col(\"identifier\").isNotNull()) & \\\n",
    "                    (col(\"holiday_indicator\").isNotNull()) & \\\n",
    "                  (col(\"item_total\")>0))  \\\n",
    "            .groupBy(\"identifier\").agg(sum(\"item_total\").alias(\"holiday_spends\"),countDistinct(\"transaction_id\").alias(\"holiday_txns\"))  \n",
    "df=df1.join(df2,\"identifier\",\"left\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmenting shoppers based on the % of holiday spends and transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------------+------------+--------------------+\n",
      "|identifier|total_spend|total_txns|holiday_spends|holiday_txns|     Type of shopper|\n",
      "+----------+-----------+----------+--------------+------------+--------------------+\n",
      "| ajb@b.com|        6.0|         1|          null|        null|Not a holiday sho...|\n",
      "| bee@f.com|       32.0|         1|          null|        null|Not a holiday sho...|\n",
      "| bnx@a.com|     679.98|         1|          null|        null|Not a holiday sho...|\n",
      "| buv@e.com|     329.22|         1|          null|        null|Not a holiday sho...|\n",
      "| ccj@e.com|       5.05|         1|          null|        null|Not a holiday sho...|\n",
      "+----------+-----------+----------+--------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = df.withColumn('Type of shopper', when((col('holiday_txns')/col('total_txns') >= 0.6) & (col('holiday_spends')/col('total_spend') >= 0.6) ,\"Holiday Shopper\") \\\n",
    "                                                 .otherwise(\"Not a holiday shopper\"))  \n",
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|     Type of shopper|count(Type of shopper)|\n",
      "+--------------------+----------------------+\n",
      "|Not a holiday sho...|                 13045|\n",
      "|     Holiday Shopper|                  1160|\n",
      "+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.groupBy(\"Type of shopper\").agg(count(\"Type of shopper\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
